{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis of 1583820 words in movie review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\bibek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews') \n",
    "from nltk.corpus import movie_reviews\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the number of words in movie reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plot', ':', 'two', 'teen', 'couples', 'go', 'to', ...]"
      ]
     },
     "execution_count": 701,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.words()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583820"
      ]
     },
     "execution_count": 702,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.words())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Categorize review words according to their sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_reviews.categories()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_reviews.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates list named documents with each element in the list containing words used in the movie review respective to their categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [(list(movie_reviews.words(fileid)), category)\n",
    "             for category in movie_reviews.categories()\n",
    "              for fileid in movie_reviews.fileids(category)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Randomly shuffles the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converts all the words in corpus to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bibek\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloads stopwords from nltk and updates file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removes all stop words and punctuations and updates it in all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = nltk.FreqDist(w.lower() for w in movie_reviews.words() if w not in stopwords if w not in string.punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creates a list named “word_features” with 2000 most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_features = sorted(list(all_words.keys()),key=all_words.get,reverse=True)[:2000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defines a document_features function that shows whether each review file contains any of the 2000 most frequent words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies the function to each element in the list documents and saves it under featuresets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(featuresets) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits “featuresets” into 100 test_set and 1900 train_set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set = featuresets[1900:], featuresets[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applies nltk’s NaiveBayes Classifier to the train_set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displays Accuracy of test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows the top 15 most informative features for movie_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(worst) = True              neg : pos    =      6.7 : 1.0\n",
      "        contains(change) = True              pos : neg    =      6.6 : 1.0\n",
      "        contains(camera) = True              neg : pos    =      6.1 : 1.0\n",
      "       contains(perfect) = True              pos : neg    =      5.9 : 1.0\n",
      "          contains(rock) = True              pos : neg    =      5.9 : 1.0\n",
      "         contains(class) = True              pos : neg    =      5.9 : 1.0\n",
      "      contains(supposed) = True              neg : pos    =      5.4 : 1.0\n",
      "    contains(considered) = True              neg : pos    =      5.4 : 1.0\n",
      "        contains(talent) = True              neg : pos    =      5.4 : 1.0\n",
      "       contains(intense) = True              pos : neg    =      5.2 : 1.0\n",
      "        contains(unique) = True              pos : neg    =      4.5 : 1.0\n",
      "         contains(truly) = True              pos : neg    =      4.5 : 1.0\n",
      "       contains(towards) = True              pos : neg    =      4.5 : 1.0\n",
      "          contains(1997) = True              pos : neg    =      4.5 : 1.0\n",
      "      contains(expected) = True              pos : neg    =      4.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twenty fold cross validation to show how the Bayes’ classifier performs over different subsets of “featuresets.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "accuracy 0.79\n",
      "2\n",
      "accuracy 0.81\n",
      "3\n",
      "accuracy 0.8\n",
      "4\n",
      "accuracy 0.78\n",
      "5\n",
      "accuracy 0.77\n",
      "6\n",
      "accuracy 0.84\n",
      "7\n",
      "accuracy 0.88\n",
      "8\n",
      "accuracy 0.86\n",
      "9\n",
      "accuracy 0.88\n",
      "10\n",
      "accuracy 0.83\n",
      "11\n",
      "accuracy 0.77\n",
      "12\n",
      "accuracy 0.83\n",
      "13\n",
      "accuracy 0.79\n",
      "14\n",
      "accuracy 0.82\n",
      "15\n",
      "accuracy 0.77\n",
      "16\n",
      "accuracy 0.82\n",
      "17\n",
      "accuracy 0.76\n",
      "18\n",
      "accuracy 0.77\n",
      "19\n",
      "accuracy 0.74\n",
      "20\n",
      "accuracy 0.8\n"
     ]
    }
   ],
   "source": [
    "accu=0\n",
    "\n",
    "for i in range(1, 21):\n",
    "    print(i)\n",
    "    train_set, test_set = featuresets[:100*(i-1)]+featuresets[100*i:], featuresets[100*(i-1):100*i]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    arate=nltk.classify.accuracy(classifier, test_set)\n",
    "    accu=accu+arate\n",
    "    print('accuracy',arate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prints the overall prediction accuracy based on the average of the 20 accuracy rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 724,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8055\n"
     ]
    }
   ],
   "source": [
    "print(accu/i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
